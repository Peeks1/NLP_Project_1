{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ps1.4-PeeksOkafor.txt\"\n",
    "val = {}\n",
    "\"\"\"\n",
    "reads the file and tokenizes the word\n",
    "\"\"\"\n",
    "def file_reading(file_name):\n",
    "    file = open(file_name)\n",
    "    f = file.read()\n",
    "    \n",
    "    word = nltk.word_tokenize(f)\n",
    "    file.close()\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reads in the tokenized words and gets the unigram count of them\n",
    "\"\"\"\n",
    "def unigram_counting(text):\n",
    "    unigram = nltk.ngrams(text,1) # does the unigram modeling\n",
    "    unigram_list = [ ' '.join(grams) for grams in unigram] ### joins the unigram into a list \n",
    "    unigram_count = len(unigram_list)\n",
    "    return unigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parses the file and gets the collocations using a sliding window method\n",
    "\"\"\"\n",
    "def collocation_calculator(file_name):\n",
    "    file = open(file_name).read()\n",
    "    sentences = nltk.sent_tokenize(file) #tokenzie the file into sentences\n",
    "    new_list = []\n",
    "    word_dict = {}\n",
    "    for i in range (len(sentences)): ## reads each sentences and removes all the new lines and punctuations from each sentence\n",
    "        s = ' '.join(sentences[i].split('\\n'))# splits the sentences where there are newlines in them\n",
    "        table = str.maketrans((string.punctuation),' '*len(string.punctuation))# replaces all punctuations with a space\n",
    "        new_s = s.translate(table) \n",
    "        new_s = new_s.lower()#pareses the words and make them all lower case\n",
    "        new_list.append(new_s) \n",
    "    collacations_counter ={}\n",
    "    for i in range(len(new_list)):\n",
    "        counter = 0\n",
    "        word = nltk.word_tokenize(new_list[i])# tokenize the words from the sentence list\n",
    "        for index in range(len(word)):# counts the frequnecy of each word in the test\n",
    "            words = word[index].lower()\n",
    "            if words in word_dict:\n",
    "                word_dict[words]+=1\n",
    "            else:\n",
    "                word_dict[words]=1\n",
    "            if len(word[index:index+4]) != 1:# makes a sliding window that gets the combination of words in the text\n",
    "                sub_list = combinations(word[index:index+4],2)\n",
    "                for item in sub_list:\n",
    "                    if item in collacations_counter: #adds them into the collocations dictionary and gets its frequnecy\n",
    "                        collacations_counter[item] +=1\n",
    "                    else:\n",
    "                        collacations_counter[item] =1\n",
    "    stoplist = []\n",
    "    for i in stopwords.words('english'):\n",
    "        stoplist.append(i)\n",
    "    stopwords.words('english')\n",
    "    for i in collacations_counter: #set all the collocations that are in the stoplist to None\n",
    "        for j in stoplist:\n",
    "            if j in i:\n",
    "                collacations_counter[i] = None\n",
    "    updated_dict = {}\n",
    "    for i in collacations_counter:#makes a new dictionary that does not contain the stoplist\n",
    "        if collacations_counter[i]!= None:\n",
    "            updated_dict[i]= collacations_counter[i]\n",
    "    return updated_dict,word_dict #gets the word count and collocations dictionaery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = file_reading(file_name)\n",
    "size = unigram_counting(text)\n",
    "val,word_count = collocation_calculator(file_name)\n",
    "\"\"\"\n",
    "does the PMI for each collocations and store their value in a dictionary that has the collocations as key\n",
    "\"\"\"\n",
    "def pointwise_mutual_information(size,collocation_count,word_count): \n",
    "    PMI = {}\n",
    "    for i in collocation_count:\n",
    "        if collocation_count[i]>2:\n",
    "            word_1 = i[0]\n",
    "            word_2 = i[1]\n",
    "            PMI[i] = math.log2(size*((collocation_count[i])/(word_count[word_1]*word_count[word_2])))\n",
    "        \n",
    "    return PMI\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI = pointwise_mutual_information(size,val,word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('overloaded', 'curriculum') 19.477042780164354\n",
      "('immature', 'pupil') 19.477042780164354\n",
      "('leo', 'lentelli') 19.477042780164354\n",
      "('lentelli', 'topped') 19.477042780164354\n",
      "('universe', 'moves') 19.477042780164354\n"
     ]
    }
   ],
   "source": [
    "# sorts the collocations in ascending order\n",
    "#prints the top five collocations\n",
    "sort_order = sorted(PMI.items(), key=lambda x:x[1], reverse=True) \n",
    "for i in range(0,5):\n",
    "    print(sort_order[i][0],sort_order[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('states', 'united') 0.6378912877573397\n",
      "('government', 'states') 0.7395627056522452\n"
     ]
    }
   ],
   "source": [
    "#prints the least two collocations\n",
    "sort_order = sorted(PMI.items(), key=lambda x:x[1]) \n",
    "for i in range(0,2):\n",
    "    print(sort_order[i][0],sort_order[i][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
