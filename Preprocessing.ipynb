{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocessing(filename):\n",
    "    f = open(filename)\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        new_lst = []\n",
    "        new_lst.append(line[0])\n",
    "        val = \" \".join(line[1:])\n",
    "        val = val.lower()\n",
    "        table = str.maketrans(string.punctuation, \" \"*len(string.punctuation))  # OR {key: None for key in string.punctuation}\n",
    "        val = val.translate(table)  \n",
    "        new_lst.append(val)\n",
    "        res.append(new_lst)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init files\n",
    "basstrain = preprocessing(\"bass_sake_train_test/bass.trn\")\n",
    "basstest = preprocessing(\"bass_sake_train_test/bass.tst\")\n",
    "saketrain = preprocessing(\"bass_sake_train_test/sake.trn\")\n",
    "saketest = preprocessing(\"bass_sake_train_test/sake.tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: find amount of each's useage in the corpus\n",
    "# step 2: for each case, collect some of the surrounding words\n",
    "bassfish = []\n",
    "bassmusic = []\n",
    "basstotal = len(basstrain)\n",
    "sakealch = []\n",
    "sakecause = []\n",
    "saketotal = len(saketrain)\n",
    "\n",
    "# sort through bass\n",
    "for line in basstrain:\n",
    "    if '*' in line[0]:\n",
    "        bassfish.append(line[1])\n",
    "    else:\n",
    "        bassmusic.append(line[1])\n",
    "\n",
    "# sort through sake\n",
    "for line in saketrain:\n",
    "    if '*' in line[0]:\n",
    "        sakealch.append(line[1])\n",
    "    else:\n",
    "        sakecause.append(line[1])\n",
    "\n",
    "# don't need the identifiers anymore, so reduce basstrain and saketrain to just\n",
    "# the sentence strings\n",
    "basstrain = [line[1] for line in basstrain]\n",
    "saketrain = [line[1] for line in saketrain]\n",
    "\n",
    "# also have some numerics stored in variables\n",
    "numbassfish = len(bassfish)\n",
    "percentfish = numbassfish/basstotal\n",
    "numbassmusic = len(bassmusic)\n",
    "percentmusic = numbassmusic/basstotal\n",
    "numsakealch = len(sakealch)\n",
    "percentalch = numsakealch/saketotal\n",
    "numsakecause = len(sakecause)\n",
    "percentcause = numsakecause/saketotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: collect features\n",
    "# feature collecting functions\n",
    "\n",
    "# create collection of nearby words\n",
    "def nearby_words(dataset, targetword):\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        for word in line.split():\n",
    "            if word != 'targetword':\n",
    "                if word in frequencydict:\n",
    "                    frequencydict[word] += 1\n",
    "                else:\n",
    "                    frequencydict[word] = 1\n",
    "    return frequencydict\n",
    "\n",
    "# create collection of words immediately to the left\n",
    "def left_words(dataset, targetword):  # this could probably be a lot more efficient\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            if line_list[i] == targetword:\n",
    "                if line_list[i - 1] in frequencydict:\n",
    "                    frequencydict[line_list[i - 1]] += 1\n",
    "                else:\n",
    "                    frequencydict[line_list[i - 1]] = 1\n",
    "    return frequencydict\n",
    "\n",
    "# create collection of words immediately to the right\n",
    "def right_words(dataset, targetword):\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            if line_list[i] == targetword:\n",
    "                if i == len(line_list) - 1:\n",
    "                    break  # stops indexing errors\n",
    "                if line_list[i + 1] in frequencydict:\n",
    "                    frequencydict[line_list[i + 1]] += 1\n",
    "                else:\n",
    "                    frequencydict[line_list[i + 1]] = 1\n",
    "    return frequencydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make freq dicts for each meaning and then for both meanings (need the latter\n",
    "# for probabilities later)\n",
    "fishfreq = nearby_words(bassfish, 'bass')\n",
    "musicfreq = nearby_words(bassmusic, 'bass')\n",
    "bassfreq = nearby_words(basstrain, 'bass')\n",
    "alchfreq = nearby_words(sakealch, 'sake')\n",
    "causefreq = nearby_words(sakecause, 'sake')\n",
    "sakefreq = nearby_words(saketrain, 'sake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dicts of words to the left and right\n",
    "fishleft = left_words(bassfish, 'bass')\n",
    "musicleft = left_words(bassmusic, 'bass')\n",
    "bassleft = left_words(basstrain, 'bass')\n",
    "alchleft = left_words(sakealch, 'sake')\n",
    "causeleft = left_words(sakecause, 'sake')\n",
    "sakeleft = left_words(saketrain, 'sake')\n",
    "fishright = right_words(bassfish, 'bass')\n",
    "musicright = right_words(bassmusic, 'bass')\n",
    "bassright = right_words(basstrain, 'bass')\n",
    "alchright = right_words(sakealch, 'sake')\n",
    "causeright = right_words(sakecause, 'sake')\n",
    "sakeright = right_words(saketrain, 'sake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: make log-likelihood decision lists\n",
    "\n",
    "# function to find P(word has certain meaning|feature present)\n",
    "def prob_meaning_given_feature(desiredmeaningfeaturefreq, totalfeaturefreq):\n",
    "    prob_of_features = {}\n",
    "    for word in totalfeaturefreq:\n",
    "        if word in desiredmeaningfeaturefreq:\n",
    "            prob_of_features[word] = desiredmeaningfeaturefreq[word]/totalfeaturefreq[word]\n",
    "        else:\n",
    "            prob_of_features[word] = 0\n",
    "    return prob_of_features\n",
    "\n",
    "# probability smoother, using Laplacian Smoothing\n",
    "def smooth_probabilities(probdict, totaltokens, alpha):\n",
    "    vocab = len(probdict)\n",
    "    smoothedprobs = {}\n",
    "    for prob in probdict:\n",
    "        smoothedprobs[prob] = (probdict[prob] * totaltokens + alpha) / (totaltokens + alpha * vocab)\n",
    "        # this is the formula m + alpha / M + alpha*V, except m = prob(m) * M\n",
    "    return smoothedprobs\n",
    "    \n",
    "# function for finding computing log-likelyhood of many features\n",
    "def log_likelyhood(probdic1, probdic2):\n",
    "    # the two dicts will have the same keys\n",
    "    loglikelyhoods = {}\n",
    "    for word in probdic1:\n",
    "        loglikelyhoods[word] = abs(math.log(probdic1[word] / probdic2[word]))\n",
    "    return loglikelyhoods\n",
    "\n",
    "# function for finding features with the highest log-likelyhoods\n",
    "def highest_likelyhoods(listoflogdicts, numvalues):\n",
    "    # has to be given to the function in the order of nearby words, left, then right\n",
    "    highest_features = ['']\n",
    "    highest_logs = [0]\n",
    "    feature = 0\n",
    "    for dic in listoflogdicts:\n",
    "        feature += 1\n",
    "        if feature == 1:\n",
    "            ftstring = 'nearby words '\n",
    "        elif ftstring == 2:\n",
    "            ftstring = 'left '\n",
    "        else:\n",
    "            ftstring = 'right '\n",
    "        for word in listoflogdicts:\n",
    "            for n in highest_logs:\n",
    "                if n < dic[word]:\n",
    "                    highest_features.insert(highest_logs.index(n), ftstring + word)\n",
    "                    highest_logs.insert(highest_logs.index(n), dic[word])\n",
    "                    highest_features = highest_features[:numvalues]\n",
    "                    highest_logs = highest_logs[:numvalues]\n",
    "                    break\n",
    "    best_features = []\n",
    "    for i in range(len(highest_logs)):\n",
    "        best_features.append([highest_features[i], highest_logs[i]])\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find smoothed probabilities of each feature (did alpha = .1 after testing\n",
    "# a few values to see how alphas change the probabilities)\n",
    "\n",
    "# nearby words\n",
    "fishnearbywordsprobs = prob_meaning_given_feature(fishfreq, bassfreq)\n",
    "fishnearbywordsprobs = smooth_probabilities(fishnearbywordsprobs, basstotal, .1)\n",
    "musicnearbywordsprobs = prob_meaning_given_feature(musicfreq, bassfreq)\n",
    "musicnearbywordsprobs = smooth_probabilities(musicnearbywordsprobs, basstotal, .1)\n",
    "alchnearbywordsprobs = prob_meaning_given_feature(alchfreq, sakefreq)\n",
    "alchnearbywordsprobs = smooth_probabilities(alchnearbywordsprobs, saketotal, .1)\n",
    "causenearbywordsprobs = prob_meaning_given_feature(causefreq, sakefreq)\n",
    "causenearbywordsprobs = smooth_probabilities(causenearbywordsprobs, saketotal, .1)\n",
    "\n",
    "# word to the left\n",
    "fishleftprobs = prob_meaning_given_feature(fishleft, bassleft)\n",
    "fishleftprobs = smooth_probabilities(fishleftprobs, basstotal, .1)\n",
    "musicleftprobs = prob_meaning_given_feature(musicleft, bassleft)\n",
    "musicleftprobs = smooth_probabilities(musicleftprobs, basstotal, .1)\n",
    "alchleftprobs = prob_meaning_given_feature(alchleft, sakeleft)\n",
    "alchleftprobs = smooth_probabilities(alchleftprobs, saketotal, .1)\n",
    "causeleftprobs = prob_meaning_given_feature(causeleft, sakeleft)\n",
    "causeleftprobs = smooth_probabilities(causeleftprobs, saketotal, .1)\n",
    "\n",
    "# word to the right\n",
    "fishrightprobs = prob_meaning_given_feature(fishright, bassright)\n",
    "fishrightprobs = smooth_probabilities(fishrightprobs, basstotal, .1)\n",
    "musicrightprobs = prob_meaning_given_feature(musicright, bassright)\n",
    "musicrightprobs = smooth_probabilities(musicrightprobs, basstotal, .1)\n",
    "alchrightprobs = prob_meaning_given_feature(alchright, sakeright)\n",
    "alchrightprobs = smooth_probabilities(alchrightprobs, saketotal, .1)\n",
    "causerightprobs = prob_meaning_given_feature(causeright, sakeright)\n",
    "causerightprobs = smooth_probabilities(causerightprobs, saketotal, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute log likelyhood of features\n",
    "\n",
    "logoffishnearby = log_likelyhood(fishnearbywordsprobs, musicnearbywordsprobs)\n",
    "logofmusicnearby = log_likelyhood(musicnearbywordsprobs, fishnearbywordsprobs)\n",
    "logofalchnearby = log_likelyhood(alchnearbywordsprobs, causenearbywordsprobs)\n",
    "logofcausenearby = log_likelyhood(causenearbywordsprobs, alchnearbywordsprobs)\n",
    "\n",
    "logoffishleft = log_likelyhood(fishleftprobs, musicleftprobs)\n",
    "logofmusicleft = log_likelyhood(musicleftprobs, fishleftprobs)\n",
    "logofalchleft = log_likelyhood(alchleftprobs, causeleftprobs)\n",
    "logofcauseleft = log_likelyhood(causeleftprobs, alchleftprobs)\n",
    "\n",
    "logoffishright = log_likelyhood(fishrightprobs, musicrightprobs)\n",
    "logofmusicright = log_likelyhood(musicrightprobs, fishrightprobs)\n",
    "logofalchright = log_likelyhood(alchrightprobs, causerightprobs)\n",
    "logofcauseright = log_likelyhood(causerightprobs, alchrightprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fd3c083ec862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# find the best features for identifying each type of the word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfishbestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighest_likelyhoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogoffishnearby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogoffishleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogoffishright\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmusicbestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighest_likelyhoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogofmusicnearby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogofmusicleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogofmusicright\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malchbestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighest_likelyhoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogofalchnearby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogofalchleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogofalchright\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcausebestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighest_likelyhoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogofcausenearby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogofcauseleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogofcauseright\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-4f01f10fd66e>\u001b[0m in \u001b[0;36mhighest_likelyhoods\u001b[1;34m(listoflogdicts, numvalues)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistoflogdicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhighest_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                     \u001b[0mhighest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhighest_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftstring\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mhighest_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhighest_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# find the best features for identifying each type of the word\n",
    "fishbestfeatures = highest_likelyhoods([logoffishnearby,logoffishleft, logoffishright], 10)\n",
    "musicbestfeatures = highest_likelyhoods([logofmusicnearby,logofmusicleft, logofmusicright], 10)\n",
    "alchbestfeatures = highest_likelyhoods([logofalchnearby,logofalchleft, logofalchright], 10)\n",
    "causebestfeatures = highest_likelyhoods([logofcausenearby,logofcauseleft, logofcauseright], 10)\n",
    "print(fishbestfeatures, musicbestfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
