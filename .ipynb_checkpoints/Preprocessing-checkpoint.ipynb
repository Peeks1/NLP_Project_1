{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocessing(filename):\n",
    "    f = open(filename)\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        new_lst = []\n",
    "        new_lst.append(line[0])\n",
    "        val = \" \".join(line[1:])\n",
    "        val = val.lower()\n",
    "        table = str.maketrans(string.punctuation, \" \"*len(string.punctuation))  # OR {key: None for key in string.punctuation}\n",
    "        val = val.translate(table)  \n",
    "        new_lst.append(val)\n",
    "        res.append(new_lst)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init files\n",
    "basstrain = preprocessing(\"bass_sake_train_test/bass.trn\")\n",
    "basstest = preprocessing(\"bass_sake_train_test/bass.tst\")\n",
    "saketrain = preprocessing(\"bass_sake_train_test/sake.trn\")\n",
    "saketest = preprocessing(\"bass_sake_train_test/sake.tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: find amount of each's useage in the corpus\n",
    "# step 2: for each case, collect some of the surrounding words\n",
    "bassfish = []\n",
    "bassmusic = []\n",
    "basstotal = len(basstrain)\n",
    "sakealch = []\n",
    "sakecause = []\n",
    "saketotal = len(saketrain)\n",
    "\n",
    "# sort through bass\n",
    "for line in basstrain:\n",
    "    if '*' in line[0]:\n",
    "        bassfish.append(line[1])\n",
    "    else:\n",
    "        bassmusic.append(line[1])\n",
    "\n",
    "# sort through sake\n",
    "for line in saketrain:\n",
    "    if '*' in line[0]:\n",
    "        sakealch.append(line[1])\n",
    "    else:\n",
    "        sakecause.append(line[1])\n",
    "\n",
    "# don't need the identifiers anymore, so reduce basstrain and saketrain to just\n",
    "# the sentence strings\n",
    "basstrain = [line[1] for line in basstrain]\n",
    "saketrain = [line[1] for line in saketrain]\n",
    "\n",
    "# also have some numerics stored in variables\n",
    "numbassfish = len(bassfish)\n",
    "percentfish = numbassfish/basstotal\n",
    "numbassmusic = len(bassmusic)\n",
    "percentmusic = numbassmusic/basstotal\n",
    "numsakealch = len(sakealch)\n",
    "percentalch = numsakealch/saketotal\n",
    "numsakecause = len(sakecause)\n",
    "percentcause = numsakecause/saketotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: collect features\n",
    "# feature collecting functions\n",
    "\n",
    "# create collection of nearby words\n",
    "def nearby_words(dataset, targetword):\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        for word in line.split():\n",
    "            if word != 'targetword':\n",
    "                if word in frequencydict:\n",
    "                    frequencydict[word] += 1\n",
    "                else:\n",
    "                    frequencydict[word] = 1\n",
    "    return frequencydict\n",
    "\n",
    "# create collection of words immediately to the left\n",
    "def left_words(dataset, targetword):  # this could probably be a lot more efficient\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            if line_list[i] == targetword:\n",
    "                if line_list[i - 1] in frequencydict:\n",
    "                    frequencydict[line_list[i - 1]] += 1\n",
    "                else:\n",
    "                    frequencydict[line_list[i - 1]] = 1\n",
    "    return frequencydict\n",
    "\n",
    "# create collection of words immediately to the right\n",
    "def right_words(dataset, targetword):\n",
    "    frequencydict = {}\n",
    "    for line in dataset:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            if line_list[i] == targetword:\n",
    "                if i == len(line_list) - 1:\n",
    "                    break  # stops indexing errors\n",
    "                if line_list[i + 1] in frequencydict:\n",
    "                    frequencydict[line_list[i + 1]] += 1\n",
    "                else:\n",
    "                    frequencydict[line_list[i + 1]] = 1\n",
    "    return frequencydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make freq dicts for each meaning and then for both meanings (need the latter\n",
    "# for probabilities later)\n",
    "fishfreq = nearby_words(bassfish, 'bass')\n",
    "musicfreq = nearby_words(bassmusic, 'bass')\n",
    "bassfreq = nearby_words(basstrain, 'bass')\n",
    "alchfreq = nearby_words(sakealch, 'sake')\n",
    "causefreq = nearby_words(sakecause, 'sake')\n",
    "sakefreq = nearby_words(saketrain, 'sake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dicts of words to the left and right\n",
    "fishleft = left_words(bassfish, 'bass')\n",
    "musicleft = left_words(bassmusic, 'bass')\n",
    "bassleft = left_words(basstrain, 'bass')\n",
    "alchleft = left_words(sakealch, 'sake')\n",
    "causeleft = left_words(sakecause, 'sake')\n",
    "sakeleft = left_words(saketrain, 'sake')\n",
    "fishright = right_words(bassfish, 'bass')\n",
    "musicright = right_words(bassmusic, 'bass')\n",
    "bassright = right_words(basstrain, 'bass')\n",
    "alchright = right_words(sakealch, 'sake')\n",
    "causeright = right_words(sakecause, 'sake')\n",
    "sakeright = right_words(saketrain, 'sake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: make log-likelihood decision lists\n",
    "\n",
    "# function to find P(word has certain meaning|feature present)\n",
    "def prob_meaning_given_feature(desiredmeaningfeaturefreq, totalfeaturefreq):\n",
    "    prob_of_features = {}\n",
    "    for word in totalfeaturefreq:\n",
    "        if word in desiredmeaningfeaturefreq:\n",
    "            prob_of_features[word] = desiredmeaningfeaturefreq[word]/totalfeaturefreq[word]\n",
    "        else:\n",
    "            prob_of_features[word] = 0\n",
    "    return prob_of_features\n",
    "\n",
    "# probability smoother, using Laplacian Smoothing\n",
    "def smooth_probabilities(probdict, totaltokens, alpha):\n",
    "    vocab = len(probdict)\n",
    "    smoothedprobs = {}\n",
    "    for prob in probdict:\n",
    "        smoothedprobs[prob] = (probdict[prob] * totaltokens + alpha) / (totaltokens + alpha * vocab)\n",
    "        # this is the formula m + alpha / M + alpha*V, except m = prob(m) * M\n",
    "    return smoothedprobs\n",
    "    \n",
    "# function for finding computing log-likelyhood of many features\n",
    "def log_likelyhood(probdic1, probdic2):\n",
    "    # the two dicts will have the same keys\n",
    "    loglikelyhoods = {}\n",
    "    for word in probdic1:\n",
    "        loglikelyhoods[word] = abs(math.log(probdic1[word] / probdic2[word]))\n",
    "    return loglikelyhoods\n",
    "\n",
    "# function for finding features with the highest log-likelyhoods\n",
    "def highest_likelyhoods(listoflogdicts, numvalues):\n",
    "    # has to be given to the function in the order of nearby words, left, then right\n",
    "    highest_features = ['']\n",
    "    highest_logs = [0]\n",
    "    feature = 0\n",
    "    for dic in listoflogdicts:\n",
    "        feature += 1\n",
    "        if feature == 1:\n",
    "            ftstring = 'nearby words '\n",
    "        elif ftstring == 2:\n",
    "            ftstring = 'left '\n",
    "        else:\n",
    "            ftstring = 'right '\n",
    "        for word in dic:\n",
    "            for n in highest_logs:\n",
    "                if n < dic[word]:\n",
    "                    highest_features.insert(highest_logs.index(n), ftstring + word)\n",
    "                    highest_logs.insert(highest_logs.index(n), dic[word])\n",
    "                    highest_features = highest_features[:numvalues]\n",
    "                    highest_logs = highest_logs[:numvalues]\n",
    "                    break\n",
    "    best_features = []\n",
    "    for i in range(len(highest_logs)):\n",
    "        best_features.append([highest_features[i], highest_logs[i]])\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find smoothed probabilities of each feature (did alpha = .1 after testing\n",
    "# a few values to see how alphas change the probabilities)\n",
    "alpha = 1\n",
    "# nearby words\n",
    "fishnearbywordsprobs = prob_meaning_given_feature(fishfreq, bassfreq)\n",
    "fishnearbywordsprobs = smooth_probabilities(fishnearbywordsprobs, basstotal, alpha)\n",
    "musicnearbywordsprobs = prob_meaning_given_feature(musicfreq, bassfreq)\n",
    "musicnearbywordsprobs = smooth_probabilities(musicnearbywordsprobs, basstotal, alpha)\n",
    "alchnearbywordsprobs = prob_meaning_given_feature(alchfreq, sakefreq)\n",
    "alchnearbywordsprobs = smooth_probabilities(alchnearbywordsprobs, saketotal, alpha)\n",
    "causenearbywordsprobs = prob_meaning_given_feature(causefreq, sakefreq)\n",
    "causenearbywordsprobs = smooth_probabilities(causenearbywordsprobs, saketotal, alpha)\n",
    "\n",
    "# word to the left\n",
    "fishleftprobs = prob_meaning_given_feature(fishleft, bassleft)\n",
    "fishleftprobs = smooth_probabilities(fishleftprobs, basstotal, alpha)\n",
    "musicleftprobs = prob_meaning_given_feature(musicleft, bassleft)\n",
    "musicleftprobs = smooth_probabilities(musicleftprobs, basstotal, alpha)\n",
    "alchleftprobs = prob_meaning_given_feature(alchleft, sakeleft)\n",
    "alchleftprobs = smooth_probabilities(alchleftprobs, saketotal, alpha)\n",
    "causeleftprobs = prob_meaning_given_feature(causeleft, sakeleft)\n",
    "causeleftprobs = smooth_probabilities(causeleftprobs, saketotal, alpha)\n",
    "\n",
    "# word to the right\n",
    "fishrightprobs = prob_meaning_given_feature(fishright, bassright)\n",
    "fishrightprobs = smooth_probabilities(fishrightprobs, basstotal, alpha)\n",
    "musicrightprobs = prob_meaning_given_feature(musicright, bassright)\n",
    "musicrightprobs = smooth_probabilities(musicrightprobs, basstotal, alpha)\n",
    "alchrightprobs = prob_meaning_given_feature(alchright, sakeright)\n",
    "alchrightprobs = smooth_probabilities(alchrightprobs, saketotal, alpha)\n",
    "causerightprobs = prob_meaning_given_feature(causeright, sakeright)\n",
    "causerightprobs = smooth_probabilities(causerightprobs, saketotal, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute log likelyhood of features\n",
    "\n",
    "logoffishnearby = log_likelyhood(fishnearbywordsprobs, musicnearbywordsprobs)\n",
    "logofmusicnearby = log_likelyhood(musicnearbywordsprobs, fishnearbywordsprobs)\n",
    "logofalchnearby = log_likelyhood(alchnearbywordsprobs, causenearbywordsprobs)\n",
    "logofcausenearby = log_likelyhood(causenearbywordsprobs, alchnearbywordsprobs)\n",
    "\n",
    "logoffishleft = log_likelyhood(fishleftprobs, musicleftprobs)\n",
    "logofmusicleft = log_likelyhood(musicleftprobs, fishleftprobs)\n",
    "logofalchleft = log_likelyhood(alchleftprobs, causeleftprobs)\n",
    "logofcauseleft = log_likelyhood(causeleftprobs, alchleftprobs)\n",
    "\n",
    "logoffishright = log_likelyhood(fishrightprobs, musicrightprobs)\n",
    "logofmusicright = log_likelyhood(musicrightprobs, fishrightprobs)\n",
    "logofalchright = log_likelyhood(alchrightprobs, causerightprobs)\n",
    "logofcauseright = log_likelyhood(causerightprobs, alchrightprobs)\n",
    "\n",
    "# note: I realized later that log_likelyhood(a, b) = log_likelyhood(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nearby words stephan', 6.803505257608338], ['nearby words weidner', 6.803505257608338], ['nearby words composer', 6.803505257608338], ['nearby words player', 6.803505257608338], ['nearby words boehse', 6.803505257608338], ['nearby words onkelz', 6.803505257608338], ['nearby words valued', 6.803505257608338], ['nearby words 250', 6.803505257608338], ['nearby words trapped', 6.803505257608338], ['nearby words room', 6.803505257608338]] \n",
      " [['nearby words society', 6.803505257608338], ['nearby words their', 6.803505257608338], ['nearby words employment', 6.803505257608338], ['nearby words an', 6.803505257608338], ['nearby words sacrifice', 6.803505257608338], ['nearby words souls', 6.803505257608338], ['nearby words doc', 6.803505257608338], ['nearby words id', 6.803505257608338], ['nearby words afe19960518', 6.803505257608338], ['nearby words 0073', 6.803505257608338]]\n"
     ]
    }
   ],
   "source": [
    "# find the best features for identifying each type of the word\n",
    "bassbestfeatures = highest_likelyhoods([logoffishnearby, logoffishleft, logoffishright], 10)\n",
    "sakebestfeatures = highest_likelyhoods([logofalchnearby, logofalchleft, logofalchright], 10)\n",
    "print(bassbestfeatures, '\\n', sakebestfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
